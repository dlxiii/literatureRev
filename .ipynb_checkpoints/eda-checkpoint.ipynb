{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67079191-f577-4b3c-9172-714312e5059d",
   "metadata": {},
   "source": [
    "# This note is for review literatures about water transport timescales\n",
    "\n",
    "The paper records are downloaded from the web of science, whith a combaination of key words.\n",
    "\n",
    "For the water transport timescales, \"bay\" and \"coastal\" are added to extract less results.\n",
    "\n",
    "Author: Yulong Wang\n",
    "\n",
    "2021-10-08\n",
    "\n",
    "Column names:\n",
    "\n",
    "* Publication Type\t\n",
    "* Authors\t\n",
    "* Book Authors\t\n",
    "* Group Authors\t\n",
    "* Book Group Authors\t\n",
    "* Researcher Ids\t\n",
    "* ORCIDs\t\n",
    "* Book Editors\t\n",
    "* Author - Arabic\t\n",
    "* Article Title\t\n",
    "* Article Title - SciELO\t\n",
    "* Article Title - SciELO\t\n",
    "* Article Title - Chinese\t\n",
    "* Article Title - Russian\t\n",
    "* Patent Number\t\n",
    "* Patent Assignee\t\n",
    "* Source Title - Arabic\t\n",
    "* Source Title\t\n",
    "* Source Title - Korean\t\n",
    "* Book Series Title\t\n",
    "* Book Series Subtitle\t\n",
    "* Volume\t\n",
    "* Issue\t\n",
    "* Special Issue\t\n",
    "* Meeting Abstract\t\n",
    "* Start Page\t\n",
    "* End Page\t\n",
    "* Article Number\t\n",
    "* DOI\t\n",
    "* Book DOI\t\n",
    "* Early Access Date\t\n",
    "* Supplement\t\n",
    "* Publication Date\t\n",
    "* Publication Year\t\n",
    "* Abstract\t\n",
    "* Abstract - Foreign\t\n",
    "* Abstract - English Transliteration \t\n",
    "* Abstract - Foreign\t\n",
    "* Abstract - Korean\t\n",
    "* Conference Title\t\n",
    "* Conference Date\t\n",
    "* Conference Sponsor\t\n",
    "* Conference Location\t\n",
    "* Times Cited, WoS Core\t\n",
    "* Times Cited, CSCD \t\n",
    "* Times Cited, RSCI\t\n",
    "* Times Cited, ARCI\t\n",
    "* Times Cited, BCI\t\n",
    "* Times Cited, SCIELO\t\n",
    "* Times Cited, All Databases\t\n",
    "* 180 Day Usage Count\t\n",
    "* Since 2013 Usage Count\t\n",
    "* ISSN\t\n",
    "* eISSN\t\n",
    "* ISBN\t\n",
    "* UT (Unique ID)\t\n",
    "* Pubmed Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037b9076-552b-43ab-9c49-4549a8574e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38a35f3d-fada-4f9c-ae70-b112a251912e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes xlrd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b925aad3-89e6-4862-acbd-3f782b70d60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/savedrecs_timescales.xls'\n",
    "df = pd.read_excel(filename, sheet_name=\"savedrecs\")\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "732fbf70-43fc-4656-97ce-926e3b5f7846",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(146, 58)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daf4878f-00b0-431d-9c79-0f16d8fbf167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /Users/yulong/anaconda3/envs/hacker\n",
      "\n",
      "  added / updated specs:\n",
      "    - wordcloud\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    wordcloud-1.8.1            |   py39h89e85a6_1         172 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         172 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  wordcloud          conda-forge/osx-64::wordcloud-1.8.1-py39h89e85a6_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates    pkgs/main::ca-certificates-2021.7.5-h~ --> conda-forge::ca-certificates-2021.5.30-h033912b_0\n",
      "  certifi            pkgs/main::certifi-2021.5.30-py39hecd~ --> conda-forge::certifi-2021.5.30-py39h6e9494a_0\n",
      "  openssl              pkgs/main::openssl-1.1.1l-h9ed2024_0 --> conda-forge::openssl-1.1.1l-h0d85af4_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "wordcloud-1.8.1      | 172 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n"
     ]
    }
   ],
   "source": [
    "!conda install --yes -c conda-forge wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "658d5254-c7bc-4481-b5d2-7095ebb12b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyqtwebengine\n",
      "  Downloading PyQtWebEngine-5.15.4-cp36.cp37.cp38.cp39-abi3-macosx_10_13_intel.whl (186 kB)\n",
      "\u001b[K     |████████████████████████████████| 186 kB 4.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: googletrans in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (3.0.0)\n",
      "Collecting PyQt5-sip<13,>=12.8\n",
      "  Downloading PyQt5_sip-12.9.0-cp39-cp39-macosx_10_9_x86_64.whl (63 kB)\n",
      "\u001b[K     |████████████████████████████████| 63 kB 6.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting PyQt5>=5.15.4\n",
      "  Downloading PyQt5-5.15.4-cp36.cp37.cp38.cp39-abi3-macosx_10_13_intel.whl (7.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.0 MB 9.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyQtWebEngine-Qt5>=5.15\n",
      "  Downloading PyQtWebEngine_Qt5-5.15.2-py3-none-macosx_10_13_intel.whl (77.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 77.9 MB 81 kB/s  eta 0:00:012    |█████▏                          | 12.6 MB 7.8 MB/s eta 0:00:09     |█████████▍                      | 22.9 MB 1.0 MB/s eta 0:00:55     |█████████▉                      | 23.9 MB 1.0 MB/s eta 0:00:54  | 27.8 MB 1.0 MB/s eta 0:00:50\n",
      "\u001b[?25hRequirement already satisfied: httpx==0.13.3 in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from googletrans) (0.13.3)\n",
      "Requirement already satisfied: sniffio in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (1.2.0)\n",
      "Requirement already satisfied: hstspreload in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (2021.10.1)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (1.5.0)\n",
      "Requirement already satisfied: httpcore==0.9.* in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (0.9.1)\n",
      "Requirement already satisfied: idna==2.* in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (2.10)\n",
      "Requirement already satisfied: certifi in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (2021.5.30)\n",
      "Requirement already satisfied: chardet==3.* in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpx==0.13.3->googletrans) (3.0.4)\n",
      "Requirement already satisfied: h11<0.10,>=0.8 in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)\n",
      "Requirement already satisfied: h2==3.* in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)\n",
      "Requirement already satisfied: hyperframe<6,>=5.2.0 in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)\n",
      "Requirement already satisfied: hpack<4,>=3.0 in /Users/yulong/anaconda3/envs/hacker/lib/python3.9/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)\n",
      "Collecting PyQt5-Qt5>=5.15\n",
      "  Downloading PyQt5_Qt5-5.15.2-py3-none-macosx_10_13_intel.whl (40.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 40.5 MB 6.4 MB/s eta 0:00:011\n",
      "\u001b[?25hInstalling collected packages: PyQt5-sip, PyQt5-Qt5, PyQtWebEngine-Qt5, PyQt5, pyqtwebengine\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spyder 4.2.5 requires pyqt5<5.13, but you have pyqt5 5.15.4 which is incompatible.\n",
      "spyder 4.2.5 requires pyqtwebengine<5.13, but you have pyqtwebengine 5.15.4 which is incompatible.\u001b[0m\n",
      "Successfully installed PyQt5-5.15.4 PyQt5-Qt5-5.15.2 PyQt5-sip-12.9.0 PyQtWebEngine-Qt5-5.15.2 pyqtwebengine-5.15.4\n"
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "# !{sys.executable} -m pip install pyqtwebengine googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "10a61ce1-07c3-4285-9e7f-c630d67cdf06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       True\n",
       "1       True\n",
       "2       True\n",
       "3       True\n",
       "4       True\n",
       "       ...  \n",
       "141     True\n",
       "142     True\n",
       "143     True\n",
       "144     True\n",
       "145    False\n",
       "Name: Abstract, Length: 146, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abst = [abst for abst in df.Abstract]\n",
    "\n",
    "df.Abstract.str.contains(\"water\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3654645b-fb06-490b-a37a-f1fc26eb0d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Contaminated',\n",
       " 'sediments',\n",
       " 'poor',\n",
       " 'water',\n",
       " 'quality',\n",
       " 'and',\n",
       " 'lost',\n",
       " 'or',\n",
       " 'altered',\n",
       " 'habitat',\n",
       " 'in',\n",
       " 'Lower',\n",
       " 'Green',\n",
       " 'Bay',\n",
       " 'and',\n",
       " 'Fox',\n",
       " 'River',\n",
       " 'in',\n",
       " 'the',\n",
       " '1980s',\n",
       " 'led',\n",
       " 'to',\n",
       " 'its',\n",
       " 'listing',\n",
       " 'as',\n",
       " 'an',\n",
       " 'Area',\n",
       " 'of',\n",
       " 'Concern',\n",
       " 'by',\n",
       " 'the',\n",
       " 'International',\n",
       " 'Joint',\n",
       " 'Commission',\n",
       " 'Previous',\n",
       " 'studies',\n",
       " 'on',\n",
       " 'the',\n",
       " 'geophysics',\n",
       " 'and',\n",
       " 'health',\n",
       " 'of',\n",
       " 'the',\n",
       " 'bay',\n",
       " 'demonstrated',\n",
       " 'the',\n",
       " 'need',\n",
       " 'for',\n",
       " 'estimates',\n",
       " 'of',\n",
       " 'transport',\n",
       " 'timescales',\n",
       " 'Such',\n",
       " 'estimates',\n",
       " 'can',\n",
       " 'contribute',\n",
       " 'to',\n",
       " 'improved',\n",
       " 'understanding',\n",
       " 'of',\n",
       " 'the',\n",
       " 'transport',\n",
       " 'and',\n",
       " 'fate',\n",
       " 'of',\n",
       " 'nutrients',\n",
       " 'contaminants',\n",
       " 'and',\n",
       " 'biogeochemical',\n",
       " 'processes',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bay',\n",
       " 'This',\n",
       " 'study',\n",
       " 'reviews',\n",
       " 'definitions',\n",
       " 'of',\n",
       " 'residence',\n",
       " 'time',\n",
       " 'and',\n",
       " 'flushing',\n",
       " 'time',\n",
       " 'estimates',\n",
       " 'the',\n",
       " 'temporal',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'flushing',\n",
       " 'time',\n",
       " 'the',\n",
       " 'spatial',\n",
       " 'and',\n",
       " 'temporal',\n",
       " 'distributions',\n",
       " 'of',\n",
       " 'residence',\n",
       " 'time',\n",
       " 'and',\n",
       " 'horizontal',\n",
       " 'diffusivities',\n",
       " 'The',\n",
       " 'study',\n",
       " 'used',\n",
       " 'a',\n",
       " 'previously',\n",
       " 'developed',\n",
       " 'hydrodynamic',\n",
       " 'model',\n",
       " 'a',\n",
       " 'drifter',\n",
       " 'experiment',\n",
       " 'a',\n",
       " 'lake',\n",
       " 'particle',\n",
       " 'transport',\n",
       " 'model',\n",
       " 'and',\n",
       " 'methods',\n",
       " 'appropriate',\n",
       " 'for',\n",
       " 'the',\n",
       " 'estimation',\n",
       " 'of',\n",
       " 'transport',\n",
       " 'timescales',\n",
       " 'The',\n",
       " 'estimated',\n",
       " 'residence',\n",
       " 'time',\n",
       " 'for',\n",
       " 'lower',\n",
       " 'Green',\n",
       " 'Bay',\n",
       " '56',\n",
       " '+/-',\n",
       " '16',\n",
       " 'days',\n",
       " 'is',\n",
       " 'smaller',\n",
       " 'than',\n",
       " 'a',\n",
       " 'previous',\n",
       " 'estimate',\n",
       " 'of',\n",
       " '190',\n",
       " 'days',\n",
       " 'for',\n",
       " 'the',\n",
       " 'whole',\n",
       " 'bay',\n",
       " 'and',\n",
       " 'had',\n",
       " 'values',\n",
       " 'similar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'estimated',\n",
       " 'flushing',\n",
       " 'times',\n",
       " 'The',\n",
       " 'closeness',\n",
       " 'between',\n",
       " 'those',\n",
       " 'timescales',\n",
       " 'demonstrates',\n",
       " 'the',\n",
       " 'important',\n",
       " 'role',\n",
       " 'of',\n",
       " 'water',\n",
       " 'exchange',\n",
       " 'across',\n",
       " 'the',\n",
       " 'Chambers',\n",
       " 'Island',\n",
       " 'transect',\n",
       " 'Flushing',\n",
       " 'time',\n",
       " 'and',\n",
       " 'residence',\n",
       " 'time',\n",
       " 'do',\n",
       " 'not',\n",
       " 'follow',\n",
       " 'the',\n",
       " 'same',\n",
       " 'trends',\n",
       " 'in',\n",
       " 'monthly',\n",
       " 'variability',\n",
       " 'because',\n",
       " 'the',\n",
       " 'former',\n",
       " 'depends',\n",
       " 'directly',\n",
       " 'on',\n",
       " 'water',\n",
       " 'exchange',\n",
       " 'across',\n",
       " 'Chambers',\n",
       " 'Island',\n",
       " 'while',\n",
       " 'the',\n",
       " 'later',\n",
       " 'depends',\n",
       " 'in',\n",
       " 'addition',\n",
       " 'on',\n",
       " 'tributary',\n",
       " 'inflows',\n",
       " 'and',\n",
       " 'the',\n",
       " 'circulation',\n",
       " 'patterns',\n",
       " 'in',\n",
       " 'the',\n",
       " 'bay',\n",
       " 'The',\n",
       " 'study',\n",
       " 'includes',\n",
       " 'a',\n",
       " 'discussion',\n",
       " 'of',\n",
       " 'the',\n",
       " 'relations',\n",
       " 'between',\n",
       " 'the',\n",
       " 'timescales',\n",
       " 'of',\n",
       " 'transport',\n",
       " 'and',\n",
       " 'the',\n",
       " 'previous',\n",
       " 'studies',\n",
       " 'of',\n",
       " 'biogeochemical',\n",
       " 'processes',\n",
       " 'such',\n",
       " 'as',\n",
       " 'trophic',\n",
       " 'conditions',\n",
       " 'spatial',\n",
       " 'distribution',\n",
       " 'of',\n",
       " 'cyanobacteria',\n",
       " 'cold-water',\n",
       " 'intrusions',\n",
       " 'and',\n",
       " 'hypoxia',\n",
       " '(C)',\n",
       " '2020',\n",
       " 'International',\n",
       " 'Association',\n",
       " 'for',\n",
       " 'Great',\n",
       " 'Lakes',\n",
       " 'Research',\n",
       " 'Published',\n",
       " 'by',\n",
       " 'Elsevier',\n",
       " 'BV',\n",
       " 'All',\n",
       " 'rights',\n",
       " 'reserved']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[word for word in df.Abstract[0].replace(',', '').replace('.', '').split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd3d4ff-e959-4c42-bf10-df1460d65ad2",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/kt/f1s29bdd133f08ty3p52plgm0000gn/T/ipykernel_23476/1990580047.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mwordcloud\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword_cloud\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWordCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollocations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'white'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/hacker/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    630\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m         \"\"\"\n\u001b[0;32m--> 632\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_generated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hacker/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mgenerate_from_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    611\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m         \"\"\"\n\u001b[0;32m--> 613\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    614\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_from_frequencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/hacker/lib/python3.9/site-packages/wordcloud/wordcloud.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    573\u001b[0m         \u001b[0mregexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m         \u001b[0mwords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mregexp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m         \u001b[0;31m# remove 's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         words = [word[:-2] if word.lower().endswith(\"'s\") else word\n",
      "\u001b[0;32m~/anaconda3/envs/hacker/lib/python3.9/re.py\u001b[0m in \u001b[0;36mfindall\u001b[0;34m(pattern, string, flags)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     Empty matches are included in the result.\"\"\"\n\u001b[0;32m--> 241\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfinditer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "from wordcloud import WordCloud\n",
    "word_cloud = WordCloud(collocations = False, background_color = 'white').generate(abst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ace5b5-cef9-400c-8daf-cb48cc13e58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
